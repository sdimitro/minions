% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
\documentclass[10pt, conference, compsocconf]{IEEEtran}
% Add the compsocconf option for Computer Society conferences.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}

% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 4.0 (2003-05-27) and later if using hyperref.sty. cite.sty does
% not currently provide for hyperlinked citations.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.


\usepackage{hyperref}



% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at: 
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found as epslatex.ps or
% epslatex.pdf at: http://www.ctan.org/tex-archive/info/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


%\usepackage{mdwmath}
%\usepackage{mdwtab}
% Also highly recommended is Mark Wooding's extremely powerful MDW tools,
% especially mdwmath.sty and mdwtab.sty which are used to format equations
% and tables, respectively. The MDWtools set is already installed on most
% LaTeX systems. The lastest version and documentation is available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/mdwtools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.


%\usepackage{eqparbox}
% Also of notable interest is Scott Pakin's eqparbox package for creating
% (automatically sized) equal width boxes - aka "natural width parboxes".
% Available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/eqparbox/





% *** SUBFIGURE PACKAGES ***
%\usepackage[tight,footnotesize]{subfigure}
% subfigure.sty was written by Steven Douglas Cochran. This package makes it
% easy to put subfigures in your figures. e.g., "Figure 1a and 1b". For IEEE
% work, it is a good idea to load it with the tight package option to reduce
% the amount of white space around the subfigures. subfigure.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at:
% http://www.ctan.org/tex-archive/obsolete/macros/latex/contrib/subfigure/
% subfigure.sty has been superceeded by subfig.sty.



%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}
% subfig.sty, also written by Steven Douglas Cochran, is the modern
% replacement for subfigure.sty. However, subfig.sty requires and
% automatically loads Axel Sommerfeldt's caption.sty which will override
% IEEEtran.cls handling of captions and this will result in nonIEEE style
% figure/table captions. To prevent this problem, be sure and preload
% caption.sty with its "caption=false" package option. This is will preserve
% IEEEtran.cls handing of captions. Version 1.3 (2005/06/28) and later 
% (recommended due to many improvements over 1.2) of subfig.sty supports
% the caption=false option directly:
%\usepackage[caption=false,font=footnotesize]{subfig}
%
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/
% The latest version and documentation of caption.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/caption/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/



%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Documentation is contained in the stfloats.sty comments as well as in the
% presfull.pdf file. Do not use the stfloats baselinefloat ability as IEEE
% does not allow \baselineskip to stretch. Authors submitting work to the
% IEEE should note that IEEE rarely uses double column equations and
% that authors should try to avoid such use. Do not be tempted to use the
% cuted.sty or midfloat.sty packages (also by Sigitas Tolusis) as IEEE does
% not format its papers in such ways.





% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/misc/
% Read the url.sty source comments for usage information. Basically,
% \url{my_url_here}.





% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Evaluating the Support of MTC Applications\\on Intel Xeon Phi Many-Core Accelerators}


% author names and affiliations
% use a multiple column layout for up to two different
% affiliations

\author{\IEEEauthorblockN{Karl Stough,
Serapheim Dimitropoulos,
Poornima Nookala}
\IEEEauthorblockA{Illinois Institute of Technology}
}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle


\begin{abstract}
As Many-Task Computing (MTC) is becoming commonplace on clusters, grids, and supercomputers, research that aims to take advantage of the new advances in hardware for MTC workloads becomes more relevant. A good example is the design of frameworks like GeMTC that incorporate general purpose GPU hardware to improve the concurrency of executing tasks. For this project we will attempt to support MTC workloads on the Intel Xeon Phi. Our plan is to develop two frameworks that will achieve that goal. One will be based on OpenMP and the other one on Intel’s Symmetric Communication Interface (SCIF) provided for Many-Integrated Core (MIC) accelerators like the Xeon Phi. Both frameworks will provide an identical interface to the one found in the GeMTC’s API aiming to work as drop-in replacements. Our end-goal is to present how programming many-core computing processors can be made easier and more productive using OpenMP or SCIF in integration with parallel languages like Swift/T.

\end{abstract}

\begin{IEEEkeywords}
Many-task computing; Accelerators; Intel Xeon Phi; Coprocessor; Programming models; Execution models.

\end{IEEEkeywords}


% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Background Information}
GeMTC is a CUDA based GPU framework which allows Many-Task Computing workloads to run efficiently on NVIDIA GPUs[1]. NVIDIA is only one manufacturer of hardware accelerators; several other brands/manufacturers include AMD GPUs and the Intel Xeon Phi. This project aims to provide support for the Intel Xeon Phi via the use of OpenMP and SCIF. The Intel Xeon Phi is a hardware coprocessor from Intel. It is a PCI device with roughly 60 cores and over 240 hardware threads. Enabling support for the Swift parallel scripting language on the Xeon Phi, through our frameworks, would contribute a great deal towards making programming many-core computing processors and accelerators easier and efficient while providing a high-level abstraction to application users.

\section{Problem Statement}
GPUs have different and restrictive programming model, but provide at least an order of magnitude better throughput for applications painstakingly coded to that model [3]. To program GPUs, typically there is a need to learn another programming language such as CUDA (NVIDIA) or OpenCL (AMD). As a result, existing vendors must spend extra time and effort to modify or rewrite parts of their codebase to take advantage of the new capabilities provided by General Purpose GPUs (GPGPUs). Besides that, barely rewriting an application just to offload computations to a GPU rarely works well. Because of the architecture of most GPUs out there, applications must be tailored from the ground up to follow the rules of the restrictive programming model of GPUs, otherwise they may suffer from severe performance penalties. Because of that, interested vendors cannot afford to go through the effort involved. Finally, while GPUs are great for massively parallel applications with thread-switching that comes almost at no cost, their performance can take a large hit when executing programs with complex logic (like complicated branching and looping for example). Therefore it may be unsuitable for certain applications of MTC.

The Intel Xeon Phi follows an alternative programming model that, although may not provide the same level of parallelism, provides more flexibility and therefore can be more suitable for certain application of MTC that GPUs are not suited for. This was the primary motivation for us to work on this project.

\section{Related Work}
The GeMTC framework and its API are limited exclusively to NVIDIA GPUs since it is developed in CUDA. Even though we will be working with OpenMP on Xeon Phi, some ideas from the CUDA version of GeMTC will still be applicable. For example using a buffer in the host’s memory that will flush tasks periodically to the device seems like a useful concept to reduce communication overhead. The actual implementation of course will have to be made from scratch since there are differences between the architecture of the Xeon Phi and the GPUs that GeMTC was initially designed for.

Moreover, there have been some preliminary results for MTC workloads on the Xeon Phi [2]. In order for these results to be acquired at that time a similar framework to GeMTC was made that used SCIF. The issue with that implementation is that it does not provide the whole feature set of GeMTC and therefore is not suitable for MTC use. Nevertheless, that initial implementation gave signs that using SCIF for direct communication between the host and the accelerator via the PCI Express bus minimized certain overheads over a similar OpenMP implementation.

\section{Proposed Solution}
The Intel Xeon Phi contains a simplified version of x86 cores, which are programmed using traditional programming languages(C, OpenMP, Pthreads) or new emerging languages (e.g. OpenCL and OpenACC) [4]. Ideally, vendors will just have to add some directives and recompile their existing software for the Xeon Phi in order to offload computation to the accelerator. The idea of having x86 cores on the accelerator implies that one can execute parallel code on it that is written for ‘normal’ computers. That also means that the Xeon Phi can handle more logically complicated programs that need to be highly parallel. Finally, under certain conditions it may be beneficial to have the whole application running natively, directly on the card [5].

Our proposed solution to the problem stated earlier is to implement two frameworks for the Xeon Phi that provide a similar interface to the GeMTC framework’s API. This way we will not only enable the support of many MTC applications of GeMTC to the Xeon Phi, but we will also be able to evaluate how well our frameworks comparing them to data from GPU applications.\\


The outline of our contributions for this project is the following:\\


\begin{itemize}
  \item Design, analyze and implement two frameworks, one in OpenMP and one in SCIF, to provide functionality identical to GeMTC and to allow MTC workloads to run on Intel Xeon Phi accelerators. The team shall attempt to duplicate GeMTC’s API for easy integration with Swift.
  \item Evaluate the performance of running concurrent homogenous and heterogeneous tasks across the Phi’s 60-core architecture (240 hardware threads) and compare it with existing the performance of existing systems.
  \item Evaluate and integrate our frameworks with Swift/T to leverage the advantages of this high-level scripting language making it a productive language for programming parallel systems.
\end{itemize}

\section{Evaluation}
The team will evaluate the performance of the OpenMP and SCIF implementations of GeMTC with that of the original CUDA framework. It is expected that the three versions will have different performance characteristics due to the differences in both hardware and software architecture. The evaluation will take place in a single node machine and then in multiple nodes using Swift/T. In order to make sure that our results will be helpful for real world use, we will start by testing the performance with Synthetic Sleep Workloads and from there move on to real-world MTC workloads launched by Swift/T.\\
\\*
The team plans to evaluate:
\\
\begin{enumerate}
  \item How efficiency is affected between the different GeMTC frameworks depending on the different task types.
  \item How does each system behaves in terms of scalability as the number of concurrent threads increases.
  \item Model the throughput of each system, both as a function of task duration as well as thread concurrency
\end{enumerate}

Additionally, the team may perform a cursory investigation into the expected performance per watt between a GPU and Xeon Phi in a real-world supercomputing setting.

\section{Timeline with weekly goals}

\textbf{March 4th to March 11th:} Develop "Sleep 0" and Matrix Multiplication examples in both frameworks for execution on the Xeon Phi.

\textbf{March 11th to March 18th:} Create request and response queues and pass Sleep tasks to the request queue, process them on Xeon Phi and get the response. Then generalize the framework by implementing the GeMTC API (Push, Poll, etc.).

\textbf{March 18th to March 25th:} Design and run some preliminary tests for functionality. Start working on the Project MidTerm Report Writeup.

\textbf{March 25th to April 1st:} Design and run throughput and efficiency tests on single node with different app kernels like 'Sleep 0' and Matrix multiplication sending homogenous and heterogenous tasks on different queues to make sure full utilization. Submit Project Midterm Report Writeup.

\textbf{April 1st to April 8th:} Identify areas of performance improvements from the experiments and fine tune the framework.

\textbf{April 8th to April 15th:} Integrate the framework with Swift/T using C wrapper from GeMTC. Start deciding on how to test it and evaluate its performance.

\textbf{April 15th to April 22nd:} Run the Swift/T tests with simulations of realistic workflow, or using an actual real-world application.

\textbf{April 22th to April 29th:} Put together the final report and presentation based on the results from our framework implementations. Present work during Final Presentations on the 29th.

\textbf{April 29th to May 4th:} Put together any feedback received from the presentation, wrap-up and submit the project's Final Report.

\newpage

\section{Deliverables}

The deliverables for this project are the following:\\

\begin{enumerate}
  \item The OpenMP and SCIF implementations of the GeMTC API.
  \item A formal report/research paper that will present our results and findings of our experiments. The same paper shall contain the reasoning behind some of the implementation details from our frameworks.
  \item The accompanied slides of the presentation that will take place at the end of the semester.
\end{enumerate}

\section{Conclusion}
Making a framework for a device with a unique architecture like the Xeon Phi is not a common task to undertake for most software developers. Therefore, we are excited to learn about the internals of the device and see how we can get the most out of it. Nevertheless, we think the most valuable experience that we are going to get will come from considering the different tradeoffs and making decisions on a design that fits the field of Many-Task Computing.

As for the goals of our project, we would like to be realistic but also set our goals high. While it is important to implement a framework that works correctly, we think that stopping there would make our project only partially successful. We want to evaluate our success in terms of the impact of our work. Thus, we would consider our project a success if it is good enough to be presented as an alternative option to the already existing systems out there. This includes doing enough testing to verify the correctness and  the usability of our framework, while doing enough benchmarking at the same time to provide an accurate picture of where it stands when compared with existing systems in terms of performance.

% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation Results}
%\label{fig_sim}
%\end{figure}

% Note that IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command, the
% \label for the overall figure must come after \caption.
% \hfil must be used as a separator to get equal spacing.
% The subfigure.sty package works much the same way, except \subfigure is
% used instead of \subfloat.
%
%\begin{figure*}[!t]
%\centerline{\subfloat[Case I]\includegraphics[width=2.5in]{subfigcase1}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{subfigcase2}%
%\label{fig_second_case}}}
%\caption{Simulation results}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.


% An example of a floating table. Note that, for IEEE style tables, the 
% \caption command should come BEFORE the table. Table text will default to
% \footnotesize as IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that IEEE does not put floats in the very first column - or typically
% anywhere on the first page for that matter. Also, in-text middle ("here")
% positioning is not used. Most IEEE journals/conferences use top floats
% exclusively. Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the \fnbelowfloat
% command of the stfloats package.

% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
\begin{thebibliography}{1}

\bibitem{IEEEhowto:skrieder}
S.~Krieder, J.~Wozniak, T.~Armstrong, M.~Wilde, D.~Katz, B.~Grimmer,
I.~Foster and I.~Raicu, \emph{"Design and Evaluation of the GeMTC
Framework for GPU-enabled Many-Task Computing"}, ACM HPDC, 2014.

\bibitem{IEEEhowto:johnson}
J.~Johnson, S.~Krieder, B.~Grimmer, J.~Wozniak, M.~Wilde and I.~Raicu,
\emph{"Understanding the Costs of Many-Task Computing Workloads
on Intel Xeon Phi Coprocessors"}, GCASR, 2013.

\bibitem{IEEEhowto:NVIDIA}
NVIDIA Inc. , \emph{"CUDA C Programming Guide v6.5, Section 5.1-5.4,
Performance Guidelines"}, 2014.

\bibitem{IEEEhowto:HPC-Book}
E.~Wang, Q.~Zhang, B.~Shen, G.~Zhang, X.~Lu, Q.~Wu and Y.~Wang,
\emph{"High-Performance Computing on the Intel Xeon Phi: How to
Fully Exploit MIC Architectures"}, Springer, 2014, pp. 3-30.

\bibitem{IEEEhowto:Intel-Systems}
Intel,
\emph{"Intel Xeon Phi Coprocessor System Software Developers Guide"},
2014.

\end{thebibliography}


\newpage

\section{Mid-Term Progress Report}

Our proposed solution is to develop two frameworks for Xeon Phi using OpenMP and 
SCIF for running Many-Task Computing workloads. The end goal is to develop a 
framework that could mimic GeMTC which allows easy integration with Swift.\\

\textbf{Proposed Solution}\\
The completed work organized by team member is the following:\\

\underline{Karl Stough} - Karl has implemented a matrix multiplication
test program to be used in benchmarking the final system. The final
benchmarking suite will be able to call this application with varying
matrix sizes which will mimic a real-world scientific application. He
has also assisted with the design of the OpenMP based framework. As
will be noted later, Poornima and Karl have derived a system that is
less dependent on queueing and more closely resembles a "traditional"
multithreaded task scheduler. The reason for that is that they came
to the conclusion that the architecture of GeMTC could not be ported
as it is for the coprocessor architecture the team is working with.\\

\underline{Poornima Nookala} - Poornima has implemented a sleep-test
program that will be used for benchmarking on the Xeon Phi. She has
also implemented a framework similar to GeMTC with the Push/Poll, Setup
and Cleanup API calls. This framework currently is designed to run
on a CPU. The reason for that and her biggest challenge was not
being able to run or test this on the Xeon Phi. Her CPU-based implementation
and the capibilities of OpenMP to offload computations to the Phi
led her and Karl to decide between two different implementations
of the GeMTC framework. The first one, would be to use her sleep-test
and Karl's matrix multiplication programs in offload mode and
having the framework run on the CPU. This way only the heavy computation
will be done in the Xeon Phi. Poornima, together with Karl, decided
that this is the best approach to proceed. The other implemenation
would be to use Serapheim's SCIF framework that runs natively on the
Phi and use OpenMP natively. Poornima has decided to evaluate this
approach too (time-permitting).\\

\underline{Serapheim Dimitropoulos} - Serapheim has developed a
framework that is almost identical to the original GeMTC framework.
The framework runs natively on the Xeon Phi, it has an incoming
and a results queue, and so far has 5 applications that can run
on it. All code is available in [1]. Of course there are a couple
of differences in Serapheim's implementation from the original
GeMTC one. Serapheim uses the SCIF API for all communication
between the host and the device, and pthreads for concurrency
and parallelism within the framework and its applications. Also,
instead of GPGPU Warps, the framework has special threads called
Masters that either execute the computation themselves if the
application is single-threaded, or they spawn worker threads
if the application is multithreaded. A special note here is
that Serapheim made the number of master threads parametrizable
by the user, unlike GPGPU Warps that are fixed in number, so
further experimentation can be done in order to get the maximum
possible performance. From the 5 application that Serapheim
developed, one of them is a sleep-test application and the
rest are different implementation of matrix multiplications.
One is naive, the second one is optimized according to CS:APP2[2],
the third one is a blocking version[3] (with a parametrizable
block/cache-size that fits exactly on a L1/L2 cache of a Xeon Phi core),
and finally a parallel version using pthreads. The major
challenge that Serapheim has faced is that he can't use SCIF
on his current hardware, even in loopback mode, so until
the team gets their hands on an actual Xeon Phi, he will
be using sockets and do everything on the CPU.\\

At this point it is worth noting again that the team has not been
given any actual hardware with a Xeon Phi available. Poornima
and Karl cannot test their offloading with OpenMP while Serapheim
cannot test his SCIF implementation for communication. In addition,
almost everything that was mentioned above is done with the assumption
that we will be able to run applications on the Phi just by recompiling
our software. Professor Raicu and his partners outside the university
have been trying hard to find some available hardware for the team
and it seems that the team might be using some machines at either
the University of Chicago or the Argonne National Laboratory.
The team expects to have access to a machine with a Xeon Phi within
this week.\\

\underline{Future work:}\\

Karl will be finishing the interface between his matrix multiplication
implementation and Poornima's framework. Poornima and Serapheim want to
finalize their framework implementations once they get access to the
required hardware. Once that is done, all team members will quickly
start evaluating their designs and run the different benchmarks described
below.\\


\textbf{Evaluation}\\

As mentioned before no evaluation has taken place because of the
lack of required hardware that we expect to get soon. Nevertheless,
the team is already planning on how to evaluate their developed
solutions.\\

\newpage

Karl is making plans on how to test the performance
of the Xeon Phi and try to compare it to a typical CPU-based
approach. He wants to showa the performance boost given by using
a Xeon Phi and the efficiency of the accelerator as the number
of concurrent threads are increased.\\

Poornima is planning to evaluate the offloading and native OpenMP
implementations and take measurments on performance, throughput
and efficiency of MTC workloads on the Xeon Phi. After that is
done she will finally fine-tune her frameworks and try to record
the maximum utilization and throughput that can be achieved.\\

Since Serapheim's implementation of GeMTC on the Phi is very close
to the original his evaluation will mostly include comparisons with
the actual GeMTC implementation. Even though he doesn't expect to
match GPGPU's performance for a massively-parallelel architecture,
he expects that for certain types and sizes of task his GeMTC implementation
can outrun the original that is made for GPUs. Specifically,
he wants to measure the communication latency between his SCIF
implementation and the original GeMTC's bulk memory and computation
offloading. Moreover, he wants to verify that the Phi can indeed
perform better on logically-complicated (meaning complicated branching)
applications as advertised. The final goal is to determine based
on the different types of tasks, which ones are more suitable for
the Xeon Phi that a GPGPU. The reason for tackling this problem
is that for future work, someone might attempt to make an intelligent
system that will look at a task and decide whether to offload it on
a GPU or a Xeon Phi in order to take the maximum throughput.\\

Unfortunately due to the lack of available hardware we are not
in track with the original timeline set in our proposal above.
There is not enough time for integration with Swift/T since
the preliminary testing on a Phi has not been done yet.\\

The team is really trying hard to find available hardware
and at the same time we don't want to speculate too much
on when we will get it since we might be completely wrong.
Therefore, the list below is to be done after we get the
hardware:\\

\textbf{5 days} - Run preliminary tests for functionality
and correctness of our programs.\\

\textbf{6 days} - Identify areas of performance improvements
and try to fine-tune the developed applications.\\

\textbf{6 days} - Execute our current plans from the Evaluation
section above.\\

\textbf{4 days} - Put together our final report and presentation
describing our work and presenting our results.\\

\textbf{3 days} - Put together any feedback received from the
presentation, wrap-up and submit the project’s Final Report.\\

\begin{thebibliography}{2}

\bibitem{IEEEhowto:mysource}
Serapheim Dimitropoulos, \emph{"GeMTC-SCIF Source Code Repository"},
\url{https://github.com/sdimitro/scif-modules/tree/master/sockets}.

\bibitem{IEEEhowto:CS2APP}
Bryant, O'Hallaron,
\emph{"Computer Systems: A Programmer's Perspective"}, 2011.

\bibitem{IEEEhowto:memblock}
Bryant, O'Hallaron,
\emph{"Using Blocking to Increase Temporal Locality"},
\url{http://csapp.cs.cmu.edu/2e/waside/waside-blocking.pdf}.

\end{thebibliography}

% that's all folks
\end{document}


